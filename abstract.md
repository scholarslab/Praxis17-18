### Spyros
A few questions about the project
- What is augmented reality? (Think about the concept of augmented reality beyond the gimmicks of contemporary technological devices)  

- Has augmented reality been imagined in the past? (who? where? how? Examples: Babage, Rabelais, others?)

- What do we exactly want to do with augmented reality? What do we want to reveal along side with what already exists? Through which senses are we augmenting (sight, hearing)? Accessibility issues? Who is our audience? How the user of our project is supposed to interact with it and what will they learn?

- What would a minimal augmented reality project be? (minimal computing, experimental and critical making, easily reproducible by others, with no use of third party proprietary software)



### Monica's Project Blurb

Research question: How do we make seemingly static places/texts talk? What can those places/texts tell us about institutional inequality?

One answer: We can use digital technologies to illuminate histories/realities that usually remain hidden. In this case study, We will use augmented reality to allow users to experience spaces and objects at the University of Virginia in new ways that prompt critical reflection on the structure, culture, mission, and history of UVA.

UVA is one case study. However, we hope that our methods can be picked up and used by other scholars to critically reexamine their own institutional histories/spaces.

### Christian Howard:

The 2017-2018 Praxis cohort at the University of Virginia is working on a project tentatively titled: *Augmenting the University*. Using augmented reality applications, this project is designed to highlight the dynamic, changing spaces across the university by making visible historical, cultural, (inter)national, (trans)sexual, and (dis)ability-related events that have occurred at the University of Virginia. In so doing, we hope to *aims*.

*Paragraph on what buildings/information we are using/drawing from.*
Our project integrates documents culled from the Albert and Shirley Small Special Collections Library.

The technology that our project employs is *??*.

To Christian: do you mean applications just in the "app" sense or also low-tech?

### Torie blurb:
Our project uses metadata analysis to inform connections between university spaces and Special Collections objects at UVa that reveal the dynamism of both the space and the object.

Ok sorry this is ending up being more like more ideas and less like a unified abstract BUT I've been thinking of ways that our project can connect library holdings/spaces/objects.

I've been reading about Linked Data which can use library catalog data and data from disparate places on the Web (or, even in other library catalogs) to match data from an object or resource with related content that goes deeper than subject matter/author/language/etc, the normal stuff you see on VIRGO, for example. Linked Data requires that resources have URIs that can be accessed quickly within ... and... I'm stretching my knowledge here so apologies if this doesn't make sense... within an RDF/SPARQL platform... (????) Connections between resources'  URIs allows for a richer process of library cataloging as well as data discovery for the user.

**Cannot actually figure out if this was/is currently a functioning app**

What I'm interested in researching is if there is a way we can merge library information into an application that uses GPS location for UVa grounds so that a space is instantly linked with special collections holdings related to that space. I know how to access the URIs for WorldCat holdings that lead to that item's Linked Data, and I'm wondering if there is a similar way to access that information directly from Virgo.

That way, we could have an app that, when you are in the Chapel, e.g., can link you to items in special collections detailing the first integrated service at the Chapel, any riots occurring at the Chapel, etc. We could also similarly allow new content to be generated by the user.

I am wondering how specific Special Collections data is, and if this would work at all. But I think that having a tool for this kind of data and research analysis is an important back end that our project needs.

Maybe parts of this ramble can be used in the abstract!

In terms of accessibility: I think that providing a more low-tech version of augmented reality by simply providing real-time resources to related content is a way to skirt around accessibility issues. Users with vision, hearing, learning, or sensory concerns generally have the proper applications on their devices to navigate regular mobile content. That being said, the necessity of having a device to access this content is limiting to those who 1) do not want to share GPS location with their service provider (if that's where we're going with this) or 2) do not have a smart phone. So I think that the backend of our project should be accessible on the internet regardless of location on grounds or smart phone access. BUT this would easily lend itself to more high-tech forms of augmented reality, not *just* the low-tech version.

Ankita:

Digital space assumes a kind of openness and easy mobility that is lacking in real space. Users can move rapidly across zones that they would not be able to in actuality. Spatial boundaries and limitations are seemingly circumvented to a large extent in the digital space. Movement may be controlled due to socio-economic and political reasons, resulting in groups of individuals who are excluded from areas. Though the university itself is a public space, it would be interesting to explore this dynamic through an interrogation of physical, real world boundaries as opposed to the boundaries (or lack thereof) in digital space. This might also tie into issues of accessibility. [Apologies since this is more an idea and not really abstract related!]

I really like Torie's idea also, though I'm not certain I understand all of it. Looking for ward to hearing more about it!

Along with the app, I think we should consider ways in which we can conduct our research, structure and present it on the web in a way that can replicate, or at least mimic, the features of augmented reality. It will not have the "cool" effect of superimposing augmented details on to real time space, but I don't think that it will be any less illuminating with respect to our research goals and objectives. The web "version" could be multi-layered in a way that points toward the "augmented" nature of the project. So even if a user is navigating through the web version of our project, they will be able to experience the same thing as the app user. In fact, the web will be more informative since it will show more clearly our research methods and findings.
